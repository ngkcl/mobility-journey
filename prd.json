{
  "project": "mobility-app",
  "branchName": "ralph/airpods-posture",
  "description": "Add AirPods head tracking for real-time slouch detection. Uses CMHeadphoneMotionManager via react-native-headphone-motion to monitor head pitch and alert when slouching.",
  "userStories": [
    {
      "id": "AP-001",
      "title": "Switch to development build with expo-dev-client",
      "description": "Replace Expo Go with a custom development build so we can use native modules like headphone motion.",
      "acceptanceCriteria": [
        "Install expo-dev-client",
        "Run npx expo prebuild to generate ios/ directory",
        "Update app.json with proper iOS bundle identifier (com.mandel.mobilityjourney)",
        "Add NSMotionUsageDescription to Info.plist: 'Mobility Journey uses AirPods motion to track your posture'",
        "Typecheck passes",
        "Project builds with npx expo run:ios (or at minimum prebuild succeeds)"
      ],
      "priority": 1,
      "passes": true,
      "notes": "This is required before any native module can work. Expo Go doesn't support custom native modules."
    },
    {
      "id": "AP-002",
      "title": "Install and configure react-native-headphone-motion",
      "description": "Add the AirPods head tracking library and create a reusable hook for accessing motion data.",
      "acceptanceCriteria": [
        "Install react-native-headphone-motion",
        "Create lib/useHeadphoneMotion.ts hook that: checks if headphone motion is available, requests permission, provides real-time pitch/roll/yaw data",
        "Hook returns: { isAvailable, isTracking, pitch, roll, yaw, startTracking, stopTracking }",
        "Graceful fallback when AirPods not connected or device doesn't support it",
        "Typecheck passes"
      ],
      "priority": 2,
      "passes": true,
      "notes": "Library: https://github.com/XHMM/react-native-headphone-motion. Requires iOS 14+. pitch = forward/back head tilt (slouching indicator), roll = side tilt, yaw = left/right rotation."
    },
    {
      "id": "AP-003",
      "title": "Slouch detection engine",
      "description": "Build the core slouch detection logic that analyzes head pitch to determine if user is slouching.",
      "acceptanceCriteria": [
        "Create lib/slouchDetector.ts with configurable thresholds",
        "Calibration: user sets their 'good posture' baseline pitch angle",
        "Slouch detected when pitch deviates beyond threshold (default: 15 degrees) for sustained period (default: 10 seconds)",
        "Three states: GOOD_POSTURE, WARNING (5-10 sec of bad posture), SLOUCHING (>10 sec)",
        "Debouncing to avoid false positives from quick glances down",
        "Export slouch events with timestamp, duration, and severity",
        "Typecheck passes"
      ],
      "priority": 3,
      "passes": true,
      "notes": "Key insight: forward head tilt (pitch going negative/down) correlates with slouching. The calibration step is critical because everyone sits differently."
    },
    {
      "id": "AP-004",
      "title": "Posture monitor screen with real-time feedback",
      "description": "Create a new tab/screen that shows real-time posture status with visual feedback.",
      "acceptanceCriteria": [
        "New 'Posture' tab in bottom navigation (replace or add alongside existing tabs)",
        "Large visual indicator: green circle = good posture, yellow = warning, red = slouching",
        "Real-time head angle display (pitch/roll gauges or simple numbers)",
        "Calibrate button: 'Sit up straight and tap to set your baseline'",
        "Session timer showing how long you've been monitoring",
        "Session stats: % time in good posture, number of slouch events, longest good streak",
        "Start/Stop monitoring toggle",
        "Works in background (keep tracking when app is minimized)",
        "Typecheck passes"
      ],
      "priority": 4,
      "passes": true,
      "notes": "This is the main screen users will interact with. Keep it simple and glanceable \u2014 big colored circle they can see at a glance."
    },
    {
      "id": "AP-005",
      "title": "Slouch alerts with haptic and sound",
      "description": "Alert the user when slouching is detected via haptic feedback and optional sound.",
      "acceptanceCriteria": [
        "Haptic feedback (gentle vibration) when slouch WARNING state is entered",
        "Stronger haptic when SLOUCHING state is entered",
        "Optional sound alert (can be toggled on/off in settings)",
        "Alert cooldown: don't spam alerts more than once per 30 seconds",
        "Settings: adjust sensitivity (threshold degrees), alert delay (seconds before alerting), enable/disable haptics, enable/disable sound",
        "Save settings to AsyncStorage",
        "Typecheck passes"
      ],
      "priority": 5,
      "passes": false,
      "notes": "Use expo-haptics for haptic feedback. Key UX: alerts should be noticeable but not annoying. The cooldown prevents alert fatigue."
    },
    {
      "id": "AP-006",
      "title": "Posture session history and Supabase logging",
      "description": "Save posture monitoring sessions to Supabase and show history.",
      "acceptanceCriteria": [
        "Create Supabase table schema for posture_sessions: id, started_at, ended_at, duration_seconds, good_posture_pct, slouch_count, avg_pitch, baseline_pitch",
        "Auto-save session when monitoring stops",
        "Posture history list showing past sessions with key stats",
        "Daily/weekly posture score trend (aggregate good_posture_pct over time)",
        "Integrate posture data into existing Progress Charts tab",
        "Typecheck passes"
      ],
      "priority": 6,
      "passes": false,
      "notes": "This connects the real-time monitoring to the existing tracking dashboard. The posture_sessions table might need to be created via Supabase dashboard \u2014 just document the schema in a migration file."
    },
    {
      "id": "AP-007",
      "title": "Camera-based posture detection (Mac webcam)",
      "description": "Use the device camera with pose estimation to detect slouching, forward head position, and shoulder asymmetry.",
      "acceptanceCriteria": [
        "Create a web-compatible posture detection module using MediaPipe Pose or TensorFlow.js BlazePose",
        "Track key landmarks: nose, ears, shoulders, and estimate head-forward angle and shoulder levelness",
        "Calibration: user sits in good posture, captures baseline landmark positions",
        "Slouch detection: compare current pose to baseline \u2014 flag when head moves forward, shoulders round, or spine curves",
        "Shoulder asymmetry detection: flag when one shoulder is consistently higher (scoliosis indicator)",
        "Visual overlay showing skeleton/landmarks on camera feed (optional, togglable)",
        "Same alert system as AirPods: green/yellow/red states with haptic-equivalent notifications",
        "Works on web (Mac webcam) and native (phone front camera for self-checks)",
        "Typecheck passes"
      ],
      "priority": 7,
      "passes": false,
      "notes": "MediaPipe Pose runs client-side in browser, no server needed. For React Native, use expo-camera + @mediapipe/pose or react-native-vision-camera with frame processors. This complements AirPods tracking \u2014 camera for desk work, AirPods for mobile."
    }
  ]
}
